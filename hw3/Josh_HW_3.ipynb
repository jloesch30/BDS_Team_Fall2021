{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDS HW 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install bs4\n",
    "!pip install csv\n",
    "!pip install PyPDF2\n",
    "!pip install tika\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T04:01:59.865669Z",
     "start_time": "2021-09-23T04:01:59.308299Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "import PyPDF2\n",
    "from tika import parser\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from math import log, e\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T01:49:34.096182Z",
     "start_time": "2021-09-23T01:49:34.084697Z"
    }
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T01:56:46.154151Z",
     "start_time": "2021-09-23T01:56:46.150413Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:51:54.215587Z",
     "start_time": "2021-09-23T02:51:39.904639Z"
    }
   },
   "outputs": [],
   "source": [
    "# URL from which pdfs to be downloaded\n",
    "url = \"http://proceedings.mlr.press/v70/\"\n",
    "  \n",
    "# Requests URL and get response object\n",
    "response = requests.get(url)\n",
    "  \n",
    "# Parse text obtained\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "  \n",
    "# Find all hyperlinks present on webpage\n",
    "links = soup.find_all('a')\n",
    "  \n",
    "i = 0\n",
    "  \n",
    "# From all links check for pdf link and\n",
    "# if present download file\n",
    "# check if links already exists\n",
    "directory = os.getcwd()\n",
    "for link in tqdm(links):\n",
    "    if ('.pdf' in link.get('href', [])):\n",
    "        i += 1\n",
    "  \n",
    "        # Get response object for link\n",
    "        response = requests.get(link.get('href'))\n",
    "  \n",
    "        # Write content in pdf file\n",
    "        # check if pdf exists already\n",
    "        if not os.path.exists(directory + \"/pdf\"+str(i)+\".pdf\"):\n",
    "            pdf = open(\"pdf\"+str(i)+\".pdf\", 'wb')\n",
    "            pdf.write(response.content)\n",
    "            pdf.close()\n",
    "  \n",
    "print(\"All PDF files downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:44:13.857029Z",
     "start_time": "2021-09-23T02:43:00.420422Z"
    }
   },
   "outputs": [],
   "source": [
    "directory = os.getcwd()\n",
    "allwords = []\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        rawText = parser.from_file(filename)\n",
    "        try:\n",
    "            pdf_words = rawText['content'].split()\n",
    "            allwords.extend([x.strip().lower() for x in pdf_words if x.strip().isalpha()])\n",
    "        except AttributeError:\n",
    "            print(f'There was an error with file: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T03:27:25.321107Z",
     "start_time": "2021-09-23T03:27:23.260334Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean words in allwords\n",
    "with open('words_dictionary.json') as json_file:\n",
    "    eng_dict = json.load(json_file)\n",
    "    allwords_clean = []\n",
    "    for word in allwords:\n",
    "        if word.lower() in eng_dict:\n",
    "            allwords_clean.append(word)\n",
    "\n",
    "# save all words clean\n",
    "text_file = open('all _words_clean.txt', 'w')\n",
    "for elem in allwords_clean:\n",
    "    text_file.write(elem+'\\n')\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:50:37.829776Z",
     "start_time": "2021-09-23T02:50:37.825728Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'The reduced word list after cleaning is: {len(allwords_clean)}\\nFrom the original: {len(allwords)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T03:32:42.582149Z",
     "start_time": "2021-09-23T03:32:42.575574Z"
    }
   },
   "source": [
    "1. What are the top 10 common words in the ICML papers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T03:31:12.175307Z",
     "start_time": "2021-09-23T03:31:11.827109Z"
    }
   },
   "outputs": [],
   "source": [
    "# find the top 10 words\n",
    "from collections import Counter\n",
    "\n",
    "def getTop10(lst):\n",
    "    counted = Counter(lst)\n",
    "    return counted.most_common(10)\n",
    "\n",
    "most_common = getTop10(allwords_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T03:31:55.893893Z",
     "start_time": "2021-09-23T03:31:55.889635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common words used are:\n",
      " [('the', 188103), ('of', 103438), ('and', 88448), ('to', 62720), ('a', 59623), ('is', 56159), ('in', 52077), ('for', 45023), ('that', 36383), ('we', 35254)]\n"
     ]
    }
   ],
   "source": [
    "print(f'The most common words used are:\\n {most_common}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Let Z be a randomly selected word in a randomly selected ICML paper. Estimate the entropy of Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T03:49:45.451160Z",
     "start_time": "2021-09-23T03:49:45.446233Z"
    }
   },
   "outputs": [],
   "source": [
    "def entropy(items, base=None):\n",
    "    n_items = len(items)\n",
    "    \n",
    "    if n_items <= 1:\n",
    "        return 0\n",
    "    \n",
    "    value, counts = np.unique(items, return_counts=True)\n",
    "    probs = counts / n_items\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    ent = 0.\n",
    "\n",
    "    # Compute entropy\n",
    "    base = e if base is None else base\n",
    "    for i in probs:\n",
    "        ent -= i * log(i, base)\n",
    "\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T03:50:40.899692Z",
     "start_time": "2021-09-23T03:50:39.180435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.725500029418058\n"
     ]
    }
   ],
   "source": [
    "print(entropy(allwords_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Synthesize a random paragraph using the marginal distribution over words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T04:01:16.925760Z",
     "start_time": "2021-09-23T04:01:16.578651Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a DF with marginal distrabution probabilities and words\n",
    "counted_words = Counter(allwords_clean)\n",
    "marginal_dist_words = {}\n",
    "n_words = len(allwords_clean)\n",
    "for key, value in counted_words.items():\n",
    "    marginal_dist_words[key] = value/n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T04:03:56.890981Z",
     "start_time": "2021-09-23T04:03:56.860993Z"
    }
   },
   "outputs": [],
   "source": [
    "marginal_dist_words_df = pd.DataFrame(marginal_dist_words.items(), columns=['word', 'distrabution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T04:07:13.623786Z",
     "start_time": "2021-09-23T04:07:13.615706Z"
    }
   },
   "outputs": [],
   "source": [
    "sampled_words = (marginal_dist_words_df.sample(n=10, weights='distrabution')['word']).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T04:07:52.149076Z",
     "start_time": "2021-09-23T04:07:52.143192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'independent cause by depending Bandits we notice dimensional is on '"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ''\n",
    "for word in sampled_words:\n",
    "    sentence += word+' '\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3: More on Kaggle Advanced Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BDS",
   "language": "python",
   "name": "bds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
